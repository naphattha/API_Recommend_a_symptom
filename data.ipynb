{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3df44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\china\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\china\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\china\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# === 1. Load Data ===\n",
    "df = pd.read_csv(\"[CONFIDENTIAL] AI symptom picker data (Agnos candidate assignment) - ai_symptom_picker.csv\")  # if downloaded as CSV\n",
    "\n",
    "\n",
    "# === 2. Extract base and detail symptoms from summary ===\n",
    "def extract_symptoms(summary_str):\n",
    "    try:\n",
    "        summary = json.loads(summary_str)\n",
    "        yes_symptoms = summary.get('yes_symptoms', [])\n",
    "        base = []\n",
    "        detail = []\n",
    "        for s in yes_symptoms:\n",
    "            base.append(s['text'].strip())\n",
    "            detail.extend([ans.strip() for ans in s.get('answers', [])])\n",
    "        return base, detail\n",
    "    except Exception:\n",
    "        return [], []\n",
    "\n",
    "df[['base_symptoms', 'detail_symptoms']] = df['summary'].apply(\n",
    "    lambda x: pd.Series(extract_symptoms(x))\n",
    ")\n",
    "\n",
    "# === 3. Add search_term symptoms as context ===\n",
    "def extract_search_terms(search_term):\n",
    "    if pd.isna(search_term):\n",
    "        return []\n",
    "    return [term.strip() for term in search_term.split(',') if term.strip()]\n",
    "\n",
    "df['search_symptoms'] = df['search_term'].apply(extract_search_terms)\n",
    "\n",
    "# === 4. Preprocess other features ===\n",
    "\n",
    "# One-hot encode gender\n",
    "ohe_gender = OneHotEncoder()\n",
    "gender_encoded = ohe_gender.fit_transform(df[['gender']]).toarray()\n",
    "\n",
    "# Bucketize age\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 20, 30, 40, 50, 100], labels=False).astype(int)\n",
    "\n",
    "# Vectorize base symptoms (from summary)\n",
    "df['base_text'] = df['base_symptoms'].apply(lambda x: ','.join(x))\n",
    "vectorizer_base = CountVectorizer(tokenizer=lambda txt: txt.split(','), binary=True)\n",
    "base_matrix = vectorizer_base.fit_transform(df['base_text'])\n",
    "\n",
    "# Vectorize detail symptoms\n",
    "df['detail_text'] = df['detail_symptoms'].apply(lambda x: ','.join(x))\n",
    "vectorizer_detail = CountVectorizer(tokenizer=lambda txt: txt.split(','), binary=True)\n",
    "detail_matrix = vectorizer_detail.fit_transform(df['detail_text'])\n",
    "\n",
    "# Vectorize search_term symptoms\n",
    "df['search_text'] = df['search_symptoms'].apply(lambda x: ','.join(x))\n",
    "vectorizer_search = CountVectorizer(tokenizer=lambda txt: txt.split(','), binary=True)\n",
    "search_matrix = vectorizer_search.fit_transform(df['search_text'])\n",
    "\n",
    "# === 5. Combine all features into single matrix ===\n",
    "X = sp.hstack([\n",
    "    gender_encoded,\n",
    "    df[['age_group']],\n",
    "    base_matrix,\n",
    "    detail_matrix,\n",
    "    search_matrix\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb87070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_row(row_dict, top_k=5):\n",
    "    gender = row_dict['gender']\n",
    "    age = int(row_dict['age'])\n",
    "    summary = row_dict['summary']\n",
    "    search_term = row_dict['search_term']\n",
    "\n",
    "    # === Extract symptoms from summary ===\n",
    "    try:\n",
    "        summary_json = json.loads(summary)\n",
    "        yes_symptoms = summary_json.get('yes_symptoms', [])\n",
    "        base_symptoms = [s['text'].strip() for s in yes_symptoms]\n",
    "        detail_symptoms = []\n",
    "        for s in yes_symptoms:\n",
    "            detail_symptoms.extend([ans.strip() for ans in s.get('answers', [])])\n",
    "    except Exception as e:\n",
    "        base_symptoms, detail_symptoms = [], []\n",
    "\n",
    "    # === Extract search terms ===\n",
    "    if pd.isna(search_term):\n",
    "        search_terms = []\n",
    "    else:\n",
    "        search_terms = [term.strip() for term in search_term.split(',') if term.strip()]\n",
    "\n",
    "    # === Encode features ===\n",
    "    gender_vec = ohe_gender.transform(pd.DataFrame({'gender': [gender]})).toarray()\n",
    "    age_group = pd.cut([age], bins=[0, 20, 30, 40, 50, 100], labels=False)[0]\n",
    "    age_vec = np.array([[age_group]])\n",
    "\n",
    "    base_text = ','.join(base_symptoms)\n",
    "    base_vec = vectorizer_base.transform([base_text])\n",
    "\n",
    "    detail_text = ','.join(detail_symptoms)\n",
    "    detail_vec = vectorizer_detail.transform([detail_text])\n",
    "\n",
    "    search_text = ','.join(search_terms)\n",
    "    search_vec = vectorizer_search.transform([search_text])\n",
    "\n",
    "    # === Combine input vector ===\n",
    "    input_vec = sp.hstack([gender_vec, age_vec, base_vec, detail_vec, search_vec])\n",
    "\n",
    "    # === Compute similarity ===\n",
    "    sims = cosine_similarity(input_vec, X).flatten()\n",
    "    top_indices = sims.argsort()[::-1][1:10]\n",
    "\n",
    "    # === Aggregate base symptoms from top similar patients ===\n",
    "    similar_base = []\n",
    "    for i in top_indices:\n",
    "        similar_base += df.iloc[i]['base_symptoms']\n",
    "\n",
    "    # === Filter and recommend ===\n",
    "    recommended = [\n",
    "        s for s in pd.Series(similar_base).value_counts().index\n",
    "        if s != \"การรักษาก่อนหน้า\"\n",
    "    ][:top_k]\n",
    "\n",
    "    return recommended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2d582e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ไอ', 'น้ำมูกไหล']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_patient = {\n",
    "    \"gender\": \"male\",\n",
    "    \"age\": 27,\n",
    "    \"summary\": '{\"diseases\": [], \"procedures\": [], \"no_symptoms\": [], \"idk_symptoms\": [], \"yes_symptoms\": [{\"text\": \"ไอ\", \"answers\": [\"ระยะเวลา 1-3 สัปดาห์\", \"ลักษณะ ไอไม่มีเสมหะ ไอแห้งๆ หรือไอเสมหะสีขาว\"]}, {\"text\": \"น้ำมูกไหล\", \"answers\": [\"ระยะเวลา 10 - 90 วัน\", \"ประวัติ ATK ทำแล้ว ได้ผลเป็นลบ\"]}, {\"text\": \"การรักษาก่อนหน้า\", \"answers\": [\"การรักษาก่อนหน้า เคยทานยาเองแล้วไม่ดีขึ้น\"]}]}',\n",
    "    \"search_term\": \"ไอ, น้ำมูกไหล\"\n",
    "}\n",
    "\n",
    "predict_from_row(new_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec81e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ปวดกระดูก', 'การได้ยินลดลง', 'ฝ้าขาวที่ลิ้น', 'ตาแดง', 'หูอื้อ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_from_row(df.iloc[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
